{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Triangle_SimCLR_Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDHi4GzkG0x5"
      },
      "source": [
        "## Top2Phase: Contrastive Learning of Water Phase from Local Topology using Edge-Conditioned Convolutional Graph Network\n",
        "\n",
        "This colab demonstrates a simple case in which I demonstrate ideas used in the Top2Phase [paper](https://console.cloud.google.com/storage/browser/simclr-checkpoints-tf2/simclrv2/pretrained). \n",
        "\n",
        "* The problem defined as follow: given a set of three node forming an isosceles triangle, learn a representation for them. \n",
        "\n",
        "* The representation is invariant to scaling of the side length. \n",
        "\n",
        "* During the training we use a uniform sampling of angle, and testing for clustering is done over discrete case (training on the discrete data set will also give the same results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZelvVBhiTDzI",
        "outputId": "798cc62c-4d05-40a7-f816-ea60d075a476"
      },
      "source": [
        "! pip install spektral==1.0.4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spektral==1.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/74/9834dc2270f19316f7a394e32525bab93a4e244760a320d5f16c82111315/spektral-1.0.4-py3-none-any.whl (116kB)\n",
            "\r\u001b[K     |██▉                             | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 20kB 20.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 30kB 10.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 61kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (2.23.0)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (2.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (0.22.2.post1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (4.2.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (1.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (1.0.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spektral==1.0.4) (1.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->spektral==1.0.4) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->spektral==1.0.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->spektral==1.0.4) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->spektral==1.0.4) (2020.12.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (2.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (0.36.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (3.12.4)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (2.4.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (1.1.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (1.32.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->spektral==1.0.4) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral==1.0.4) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->spektral==1.0.4) (2.8.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->spektral==1.0.4) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.1.0->spektral==1.0.4) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (2.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (1.30.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (3.3.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (4.0.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->spektral==1.0.4) (3.4.1)\n",
            "Installing collected packages: spektral\n",
            "Successfully installed spektral-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z0I-SAITgc_",
        "outputId": "c077f3ea-0506-469e-e97f-bbfe867754fc"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from spektral.data import Dataset, DisjointLoader, Graph\n",
        "from tensorflow.keras.layers import Dense, Input, ReLU, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import tensorflow as tf\n",
        "\n",
        "from spektral.transforms.normalize_adj import NormalizeAdj\n",
        "from spektral.data import BatchLoader\n",
        "from spektral.layers import ECCConv, GlobalSumPool, GlobalAvgPool, GlobalAttnSumPool, GlobalMaxPool\n",
        "import requests\n",
        "import spektral\n",
        "from tensorflow.keras.losses import Loss \n",
        "from spektral.layers import ECCConv, GlobalSumPool, GlobalAvgPool, GCNConv\n",
        "print(spektral.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCtirxCnThCO"
      },
      "source": [
        "################################################################################\n",
        "# LOAD DATA\n",
        "################################################################################\n",
        "class MyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    A dataset of Isosceles Triangle Represented by Graphs.\n",
        "    The task is to learn a representation without labels, which is consistent with\n",
        "    the angle of traingle. To do so, we use constrative learning with edge information.\n",
        "    We permute graphs by stochastic scaling of orignal triangle edges. \n",
        "    we show efficiency of such representations by comparing clustering results of\n",
        "    encoded representation, which turns out consistent with labels, without knowing \n",
        "    labels.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_samples, mode_cosine='disceret', **kwargs):\n",
        "        self.n_samples = n_samples\n",
        "        self.mode_cosine = mode_cosine\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def read(self):\n",
        "        def make_graph():\n",
        "            x = np.zeros((3,2))\n",
        "            x[0,0] = 1.0\n",
        "            x[1:,1] = 1.0\n",
        "            a = np.ones((3,3)) - np.eye(3)\n",
        "            a = a.astype(int)\n",
        "            if self.mode_cosine == 'uniform':\n",
        "              cost = np.random.uniform(-1,1,(1,))\n",
        "            elif self.mode_cosine == 'disceret':\n",
        "              cost = np.array([np.random.choice([-0.75, -0.5, -0.25, 0.0, 0.25, 0.5, 0.75])])#np.random.uniform(-1,1,(1,)) #\n",
        "            else:\n",
        "              raise NameError(\"Pick the right name for cosine sampling! Or implement it!\")\n",
        "            r1 = np.random.uniform(0.6,1.4, 1)\n",
        "            r2 = r1\n",
        "            e = np.zeros((3,3,1))\n",
        "            e[0,1] = r1\n",
        "            e[0,2] = r2\n",
        "            e[1,0] = r1\n",
        "            e[2,0] = r2\n",
        "            e[1,2] = (r1**2+r2**2-2*cost[0]*r1*r2)**0.5\n",
        "            e[2,1] = e[1,2]\n",
        "            e = np.concatenate([e,np.random.uniform(0.8,1.2,1)*e],axis=-1)\n",
        "            e = e.reshape((3,3,2))\n",
        "            y = cost #np.array([cost[0],r1,r2]).reshape((-1))\n",
        "            return Graph(x=x, a=a, e=e, y=y)\n",
        "        # We must return a list of Graph objects\n",
        "        return [make_graph() for _ in range(self.n_samples)]\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NzWenv5Ti0F"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "Output_dim = 64\n",
        "Latent_dim = 8\n",
        "Node_dim = 2\n",
        "Edge_dim = 1\n",
        "Weight_decay = 0.00005 # if you want to regulairze layers use it, works fine without it\n",
        "Dropout_rate = 0.01\n",
        "Kernel_network =[10,10]\n",
        "X_in = Input(shape=(None, Node_dim))\n",
        "A_in = Input(shape=(None, None))\n",
        "E_in = Input(shape=(None, None, Edge_dim))\n",
        "\n",
        "X_1 = ECCConv(4,  kernel_network=Kernel_network, activation=\"relu\")([X_in, A_in, E_in])\n",
        "X_2 = ECCConv(8, kernel_network=Kernel_network, activation=\"relu\")([X_1, A_in, E_in])\n",
        "X_3 = ECCConv(16, kernel_network=Kernel_network, activation=\"relu\")([X_2, A_in, E_in])\n",
        "X_4 = GlobalAttnSumPool()(X_3)\n",
        "\n",
        "X_4normalized =  tf.math.l2_normalize(X_4, axis=1, name='normalized') \n",
        "\n",
        "X_5 = Dense(Output_dim, activation=\"relu\", name='projector_in')(X_4normalized)\n",
        "X_5d = tf.keras.layers.Dropout(rate=Dropout_rate, name='droupout')(X_5)\n",
        "X_6 = Dense(Output_dim, use_bias=False, name='projector_head')(X_5d)\n",
        "\n",
        "model = Model(inputs=[X_in, A_in, E_in], outputs=X_6)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O7ui5RvTpSZ"
      },
      "source": [
        "lr = 0.005\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "samples = 1280\n",
        "dataset = MyDataset(samples,mode_cosine='uniform', transforms=NormalizeAdj())\n",
        "loader_tr = BatchLoader(dataset, batch_size=batch_size, epochs=epochs)\n",
        "opt = Adam(lr=lr)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Fu8ibhU19O",
        "outputId": "0167335d-f5db-4eb7-d82a-0786844988f1"
      },
      "source": [
        "loader_tr.tf_signature()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((TensorSpec(shape=(None, None, 2), dtype=tf.float64, name=None),\n",
              "  TensorSpec(shape=(None, None, None), dtype=tf.float64, name=None),\n",
              "  TensorSpec(shape=(None, None, None, 2), dtype=tf.float64, name=None)),\n",
              " TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXr9Cj5n8qZ8",
        "outputId": "1d5644a9-2432-4579-f4ba-5246d47a6d49"
      },
      "source": [
        "global Temp \n",
        "Temp = 0.6\n",
        "\n",
        "@tf.function(input_signature=loader_tr.tf_signature(), experimental_relax_shapes=True)\n",
        "def train_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        #print(inputs[0])\n",
        "        e1 = inputs[2][:,:,:,0]\n",
        "        e2 = inputs[2][:,:,:,1]\n",
        "        #e1, e2 = e[::2], e[1::2]\n",
        "        zi = model([inputs[0], inputs[1], e1], training =True)\n",
        "        zj = model([inputs[0], inputs[1], e2], training =True)\n",
        "        #zj = tf.stop_gradient(zj)\n",
        "        zi = tf.math.l2_normalize(zi, axis=1)\n",
        "        zj = tf.math.l2_normalize(zj, axis=1)\n",
        "        zi = tf.reshape(zi, (-1,zi.shape[1]))\n",
        "        zj = tf.reshape(zj, (-1,zi.shape[1]))\n",
        "        z = tf.cast(tf.concat((zi, zj), 0), dtype=tf.float32)\n",
        "        loss = 0.0\n",
        "        tau = Temp\n",
        "        batch_size = tf.shape(zi)[0]\n",
        "        for k in range(batch_size):\n",
        "            # Numerator (compare i,j & j,i)\n",
        "            i = k\n",
        "            j = k + batch_size\n",
        "            # Instantiate the cosine similarity loss function\n",
        "            cosine_sim = tf.keras.losses.CosineSimilarity(axis=-1, reduction=tf.keras.losses.Reduction.NONE)\n",
        "            #cosine_sim = tf.keras.losses.MeanSquaredError(axis=-1, reduction=tf.keras.losses.Reduction.NONE)\n",
        "            sim = tf.squeeze(- cosine_sim(tf.reshape(z[i], (1, -1)), tf.reshape(z[j], (1, -1))))\n",
        "            numerator = tf.math.exp(sim / tau)\n",
        "\n",
        "            # Denominator (compare i & j to all samples apart from themselves)\n",
        "            sim_ik = - cosine_sim(tf.reshape(z[i], (1, -1)), z[tf.range(batch_size) != i])\n",
        "            sim_jk = - cosine_sim(tf.reshape(z[j], (1, -1)), z[tf.range(batch_size) != j])\n",
        "            denominator_ik = tf.reduce_sum(tf.math.exp(sim_ik / tau))\n",
        "            denominator_jk = tf.reduce_sum(tf.math.exp(sim_jk / tau))\n",
        "\n",
        "            # Calculate individual and combined losses\n",
        "            loss_ij = - tf.math.log(numerator / denominator_ik)\n",
        "            loss_ji = - tf.math.log(numerator / denominator_jk)\n",
        "            #print(type(loss_ij), type(denominator_jk))\n",
        "            loss += tf.add(loss_ij , loss_ji)\n",
        "        \n",
        "        # Divide by the total number of samples\n",
        "        loss /= tf.cast(batch_size,tf.float32)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    opt.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "print(\"Fitting model\")\n",
        "current_batch = 0\n",
        "model_loss = 0\n",
        "current_epoch = 0\n",
        "for batch in loader_tr: \n",
        "    inps, targets = batch\n",
        "    outs = train_step(*batch)\n",
        "    model_loss += outs\n",
        "    current_batch += 1\n",
        "    if current_batch % (loader_tr.steps_per_epoch)  == 0:\n",
        "        print(\"Epoch: {} , Loss: {} \".format(current_epoch, model_loss / loader_tr.steps_per_epoch))\n",
        "        model_loss = 0\n",
        "        current_epoch +=1 \n",
        "        current_batch = 0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting model\n",
            "Epoch: 0 , Loss: 7.102535247802734 \n",
            "Epoch: 1 , Loss: 6.262664318084717 \n",
            "Epoch: 2 , Loss: 6.094189643859863 \n",
            "Epoch: 3 , Loss: 5.951582908630371 \n",
            "Epoch: 4 , Loss: 5.902822494506836 \n",
            "Epoch: 5 , Loss: 5.828078269958496 \n",
            "Epoch: 6 , Loss: 5.804168224334717 \n",
            "Epoch: 7 , Loss: 5.780106067657471 \n",
            "Epoch: 8 , Loss: 5.765320777893066 \n",
            "Epoch: 9 , Loss: 5.727412223815918 \n",
            "Epoch: 10 , Loss: 5.776583194732666 \n",
            "Epoch: 11 , Loss: 5.789846897125244 \n",
            "Epoch: 12 , Loss: 5.720215797424316 \n",
            "Epoch: 13 , Loss: 5.730053424835205 \n",
            "Epoch: 14 , Loss: 5.697445869445801 \n",
            "Epoch: 15 , Loss: 5.658745765686035 \n",
            "Epoch: 16 , Loss: 5.668644428253174 \n",
            "Epoch: 17 , Loss: 5.650498867034912 \n",
            "Epoch: 18 , Loss: 5.625554084777832 \n",
            "Epoch: 19 , Loss: 5.646111488342285 \n",
            "Epoch: 20 , Loss: 5.646829128265381 \n",
            "Epoch: 21 , Loss: 5.649102210998535 \n",
            "Epoch: 22 , Loss: 5.671175003051758 \n",
            "Epoch: 23 , Loss: 5.612756252288818 \n",
            "Epoch: 24 , Loss: 5.613945960998535 \n",
            "Epoch: 25 , Loss: 5.590141296386719 \n",
            "Epoch: 26 , Loss: 5.578570365905762 \n",
            "Epoch: 27 , Loss: 5.58917236328125 \n",
            "Epoch: 28 , Loss: 5.633333683013916 \n",
            "Epoch: 29 , Loss: 5.6932244300842285 \n",
            "Epoch: 30 , Loss: 5.631388187408447 \n",
            "Epoch: 31 , Loss: 5.575606346130371 \n",
            "Epoch: 32 , Loss: 5.60068941116333 \n",
            "Epoch: 33 , Loss: 5.597336769104004 \n",
            "Epoch: 34 , Loss: 5.574698448181152 \n",
            "Epoch: 35 , Loss: 5.536152362823486 \n",
            "Epoch: 36 , Loss: 5.564966678619385 \n",
            "Epoch: 37 , Loss: 5.547039031982422 \n",
            "Epoch: 38 , Loss: 5.543917655944824 \n",
            "Epoch: 39 , Loss: 5.54827880859375 \n",
            "Epoch: 40 , Loss: 5.558209419250488 \n",
            "Epoch: 41 , Loss: 5.550991058349609 \n",
            "Epoch: 42 , Loss: 5.53161096572876 \n",
            "Epoch: 43 , Loss: 5.52931547164917 \n",
            "Epoch: 44 , Loss: 5.537735939025879 \n",
            "Epoch: 45 , Loss: 5.521231651306152 \n",
            "Epoch: 46 , Loss: 5.514113426208496 \n",
            "Epoch: 47 , Loss: 5.52579927444458 \n",
            "Epoch: 48 , Loss: 5.527037143707275 \n",
            "Epoch: 49 , Loss: 5.5127434730529785 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSa9TBl6ZuUz",
        "outputId": "96337735-a235-4a26-b0f2-b6a65b95d99c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 2)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, None)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ecc_conv (ECCConv)              (None, None, 4)      206         input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ecc_conv_1 (ECCConv)            (None, None, 8)      494         ecc_conv[0][0]                   \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "ecc_conv_2 (ECCConv)            (None, None, 16)     1646        ecc_conv_1[0][0]                 \n",
            "                                                                 input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "global_attn_sum_pool (GlobalAtt (None, 16)           16          ecc_conv_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.l2_normalize (TFOpLambd (None, 16)           0           global_attn_sum_pool[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "projector_in (Dense)            (None, 64)           1088        tf.math.l2_normalize[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "droupout (Dropout)              (None, 64)           0           projector_in[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "projector_head (Dense)          (None, 64)           4096        droupout[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 7,546\n",
            "Trainable params: 7,546\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGqan-1B8qLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132e77dd-308c-4e3d-8955-6c1b2faa4f66"
      },
      "source": [
        "dataset = MyDataset(1280, transforms=NormalizeAdj())\n",
        "loader_tr = BatchLoader(dataset, batch_size=dataset.n_samples, epochs=1)\n",
        "for b in loader_tr:\n",
        "  inps, targets = b\n",
        "model_enc = Model(inputs=model.input, outputs=model.get_layer('tf.math.l2_normalize').output)\n",
        "\n",
        "\n",
        "print(inps[2].shape)\n",
        "\n",
        "e1 = inps[2][:,:,:,0].reshape((-1,3,3,1))\n",
        "e2 = inps[2][:,:,:,1].reshape((-1,3,3,1))\n",
        "z = model_enc([inps[0],inps[1],e1])\n",
        "z2 =  model_enc([inps[0],inps[1],e2])\n",
        "for i in range(5):\n",
        "  print(np.dot(z[0], z[i]), targets[0], targets[i], np.unique(e1[i]),np.unique(e2[i]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1280, 3, 3, 2)\n",
            "0.9999998 [0.] [0.] [0.         1.23993661 1.75353517] [0.         1.33024081 1.8812446 ]\n",
            "0.5680334 [0.] [-0.75] [0.         0.81316549 1.52129332] [0.         0.68817386 1.28745541]\n",
            "0.9998236 [0.] [0.] [0.         1.27421765 1.80201588] [0.         1.27604498 1.80460012]\n",
            "0.93104684 [0.] [-0.25] [0.        1.2595591 1.9915378] [0.         1.45054998 2.2935209 ]\n",
            "0.6112633 [0.] [0.75] [0.         0.96848572 1.36964564] [0.         1.10505663 1.56278607]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47VJUKEahbg3",
        "outputId": "d490e214-53e2-4ea1-fe7f-c85c005aa8f6"
      },
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "n_clusters=7\n",
        "clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity=\"cosine\",linkage='single').fit_predict(z/np.linalg.norm(z,1).reshape((-1,1)))\n",
        "clustering[:5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 6, 5, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3GaGuZ_hpqn",
        "outputId": "509e499c-9321-4bdf-e730-f3db501144cb"
      },
      "source": [
        "print(\"real clusters means: \", np.unique(targets))\n",
        "print(\"cluster:   c ,  mean(anlge[c]), std(angle[c]), boolen(|angle[c]| == |real(angle)|)\")\n",
        "for i in range(n_clusters):\n",
        "  idx = np.where(clustering==i)[0]\n",
        "  print(\"cluster : \", i, \",  \" ,np.mean(targets[idx]), \"        ,    \" , np.std(targets[idx]), \"       ,   \" , idx.shape[0]/clustering.shape[0] == np.where(np.abs(targets-np.mean(targets[idx]))<0.02)[0].shape[0]/clustering.shape[0])#, targets[idx]>)#, np.mean(inps[2][idx]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "real clusters means:  [-0.75 -0.5  -0.25  0.    0.25  0.5   0.75]\n",
            "cluster:   c ,  mean(anlge[c]), std(angle[c]), boolen(|angle[c]| == |real(angle)|)\n",
            "cluster :  0 ,   -0.5         ,     0.0        ,    True\n",
            "cluster :  1 ,   0.75         ,     0.0        ,    True\n",
            "cluster :  2 ,   -0.25         ,     0.0        ,    True\n",
            "cluster :  3 ,   0.25         ,     0.0        ,    True\n",
            "cluster :  4 ,   0.5         ,     0.0        ,    True\n",
            "cluster :  5 ,   0.0         ,     0.0        ,    True\n",
            "cluster :  6 ,   -0.75         ,     0.0        ,    True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr52_g1b-Eyz"
      },
      "source": [
        "* The clusters are accurate and consistent with the original labels. \n",
        "* The network might be large or small, I didn't optimize it further.\n",
        "* Feel free to experiment with number of cluster and networks architecture."
      ]
    }
  ]
}